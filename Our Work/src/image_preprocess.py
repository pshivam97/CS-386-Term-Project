# -*- coding: utf-8 -*-
"""HTR-5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EuAcU9eWQIA-Uy0S4RGTi6XDbXLEB6vi
"""

# # Connecting to Google drive
# import os
# from google.colab import drive
# drive.mount('drive')
# project_directory = 'drive/My Drive/ml_data/ai-htr/'
# os.chdir(project_directory)

"""# References
* https://pillow.readthedocs.io/en/5.3.x/handbook/tutorial.html
* https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_thresholding/py_thresholding.html
* [Maximum Sum Rectangular Submatrix in Matrix dynamic programming/2D kadane](https://www.youtube.com/watch?v=yCQN096CwWM)
"""

# Library Imports

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import os

import numpy as np

# This function will display image given the numpy ndarray

import cv2
from matplotlib import pyplot as plt

def disp_image(M):
  plt.imshow(M)
  plt.show()

# This function will return maximum sum subarray
def kadane(A):
  A = np.array(A)
  n = len(A)
  k = 1
  y = A[0]
  t = A[0]
  l = 0
  r = 0
  ltmp = 0
  rtmp = 0
  while k != n:
    if t + A[k] > A[k] :
      t = t + A[k]
    else:
      t = A[k]
      ltmp = k
    rtmp += 1

    if t > y :
      y = t
      l = ltmp
      r = rtmp
    k = k + 1
  return y, l, r


def SubRectangularMatrixWithMaximumSumHorizontalAndVertical(M):
  M = np.array(M)
  H, W = M.shape

  _, max_L, max_R = kadane(np.sum(M,axis=0))
  _, max_U, max_D = kadane(np.sum(M,axis=1))

  return max_L, max_R, max_U, max_D

# This function will remove extra spaces in image from all four sides
def remove_space(M, weight_of_dark = -1, weight_of_light = 100):

  # Converting to np array
  M = np.array(M)

  # Reweight matrix
  assign_weight = lambda x: weight_of_light if x == 0 else weight_of_dark

  vfw = np.vectorize(assign_weight)
  MW = vfw(M) # Weighted matrix

  # Return result
  max_L, max_R, max_U, max_D = SubRectangularMatrixWithMaximumSumHorizontalAndVertical(MW)
  return M[max_U:max_D+1,max_L:max_R+1]

# This function will return a list points, where each point in a separate space between words
def get_cutpoints(M):
  gamma = int(M.shape[0] / 2)

  M = np.array(M)
  M = np.sum(M,axis=0) # Summing every column of image_array
  M = (max(M) - min(M)) - (M - min(M)) # Normalize

  threshold = np.average(M) / 5

  cutpoint_list = []

  counter = 0

  for i in range(len(M)):
    if counter == gamma:
      cutpoint_list.append(i)
    if M[i] < threshold:
      counter += 1
    else:
      counter = 0

  return cutpoint_list

# This function will return the images of words given the image of sentence and cutpoints
def get_words_image(M,cutpoint_list):
  M = np.array(M)
  cutpoint_list = [0] + cutpoint_list + [M.shape[1]]
  word_images = []
  for x in range(len(cutpoint_list)-1):
    word_images.append(M[:,cutpoint_list[x]:cutpoint_list[x+1]])

  return word_images

# Library Imports

import numpy as np
import pandas as pd
from PIL import Image
import cv2


# Function to view image in jupyter notebook
from IPython.display import display
from IPython.display import Image as _Imgdis

def ishow(filename):
    display(_Imgdis(filename, height=100))

# Convert individual grayscale pixel to binary
convert_to_binary = lambda x: 0 if x<128 else 255

# Input : Location of an image of a sentence
# Output : List containing the locations of images of words
#
# Other Work Done :
# It saves the images of words in current working directory
# It also displays the image of sentence and images of words

def split_sentence(image_location):
  # Variables
  blur_amount_factor = 50

  # Opening image
  current_image = cv2.imread(image_location)

  # Converting it to greyscale
  current_image = cv2.cvtColor(current_image,cv2.COLOR_BGR2GRAY)

  # Saving height and width
  orig_height , orig_width = current_image.shape

  # Apply filter to remove noise
  blur_amount = orig_height // blur_amount_factor
  if blur_amount % 2 == 0 :
    blur_amount += 1
  current_image = cv2.medianBlur(current_image, blur_amount)

  # Converting picture to binary
  vf = np.vectorize(convert_to_binary)
  current_image = vf(current_image)

  # Remove extra spaces around sentence
  current_image = remove_space(current_image)

  # Getting cutpoints
  cutpoint_list = get_cutpoints(current_image)

  # Getting images of words
  word_images = get_words_image(current_image, cutpoint_list)

  # Remove extra space around words
  word_images = [remove_space(x) for x in word_images]

  # Resizing every word image to make height equal to 50
  word_images = [cv2.resize(x, (int(x.shape[1]*(100/x.shape[0])),int(x.shape[0]*(100/x.shape[0]))), interpolation = cv2.INTER_NEAREST) for x in word_images]

  # Saving word images in current directory
  paths = []
  for i in range(len(word_images)):
      cv2.imwrite('w'+str(i+1)+'.png',word_images[i])
      paths.append('w'+str(i+1)+'.png')

  return paths
